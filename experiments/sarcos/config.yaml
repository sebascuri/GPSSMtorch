experiment:
  name: sarcos
  splits: [['model', 'name'], ['dataset', 'sequence_length']]

dataset:
  name: Sarcos
  sequence_length: [20, 50, 100]
  sequence_stride: 1

optimization:
  learning_rate: 0.05
  batch_size: 32
  num_epochs: 10
  curriculum: False # Flag that indicates if there is a curriculum.

evaluation:
  plots: ['training_loss', 'prediction']
  length: []  # Here add extra evaluation lengths.

model:
  name: ['PRSSM', 'CBFSSM', 'VCDT']
  dim_states: 14
  num_particles: 50
  loss_key: 'elbo'
  k_factor: 1.0  # This is the soft conditioning factor.
  loss_factors:  # These factors multiply each term of the ELBO.
    loglik: 1.0 # Log-likelihood factor.
    kl_uf: 1.0  # KL-divergence of the variational distribution (with prior) of the forward model factor.
    kl_ub: 1.0  # KL-divergence of the variational distribution (with prior) of the backward model factor.
    kl_x: 1.0  # KL-divergence of the output of the recognition model (with prior p(x1)) factor.
    kl_conditioning: 1.0 # KL-divergence of the conditioning step (prediction vs. conditioning).
    entropy: 0.0  # Entropy of the backwards model predictions.
  recognition:
    length: 1
    kind: 'output'  # output, zero, nn, conv, lstm, bi-lstm.
    variance: 0.0001
    learnable: False
  emissions:
    variance: 0.0025
    learnable: False
  transitions:
    variance: 0.0002
    learnable: False
  forward:
    mean:
      kind: 'zero'  # zero, constant, linear.
    kernel:
      shared: True
      kind: 'rbf'  # rbf, matern 1/2, matern 3/2, matern 5/2, linear
      ard_num_dims:  # if empty will automatically select dim_states + dim_inputs.
      outputscale: 0.25
      lengthscale: 2.0
      learn_outputscale: True
      learn_lengthscale: True
    inducing_points:
      number_points: 50
      strategy: 'uniform'
      scale: 6.0
      learnable: True
    variational_distribution:
      learn_mean: True
      mean: 0.0
      learn_var: True
      var: 0.001